{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9763d715-563b-444e-9ee7-008599713d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\MonsuratAyinde\\Desktop\\data_multiclass\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    " # Set the working directory to Desktop\n",
    "os.chdir(r\"C:\\Users\\MonsuratAyinde\\Desktop\\data_multiclass\")\n",
    "\n",
    "# Confirm the change\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ac1eae6-38ae-46e8-a6d1-30a301be5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.version import __version__ as tqdm__version__\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59869ed3-304b-48ae-9842-d35629e653e8",
   "metadata": {},
   "source": [
    "we'll print out the version numbers for our libraries, including Python. We want to make sure that anyone who reviews our work knows exactly what software we used in case they want to reproduce our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454429e7-9714-4569-9b74-11714c7c1354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: win32\n",
      "Python version: 3.13.2 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:49:14) [MSC v.1929 64 bit (AMD64)]\n",
      "---\n",
      "CV2 version :  4.11.0\n",
      "matplotlib version :  3.10.0\n",
      "numpy version :  2.2.4\n",
      "torch version :  2.7.0+cpu\n",
      "torchinfo version :  1.8.0\n",
      "torchvision version :  0.22.0+cpu\n",
      "PIL version :  11.1.0\n",
      "scikit-learn version:  1.6.1\n",
      "tqdm version:  4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"CV2 version : \", cv2.__version__)\n",
    "print(\"matplotlib version : \", matplotlib.__version__)\n",
    "print(\"numpy version : \", np.__version__)\n",
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"torchinfo version : \", torchinfo.__version__)\n",
    "print(\"torchvision version : \", torchvision.__version__)\n",
    "print(\"PIL version : \", PIL.__version__)\n",
    "print(\"scikit-learn version: \", sklearn.__version__)\n",
    "print(\"tqdm version: \", tqdm__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd00a39-af13-4386-b805-c9c55d861aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fbf41e1-60fa-4893-8f2e-05dfbaa21d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Directory: data_binary\n",
      "Training Data Directory: data_binary\\train\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"data_binary\")\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "\n",
    "print(\"Data Directory:\", data_dir)\n",
    "print(\"Training Data Directory:\", train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b7d83-7de5-42e6-828e-ad77de9062c6",
   "metadata": {},
   "source": [
    "Since we're doing binary classification, we'll have two different labels. The data for each label is separated into their own folder. The name of the folder corresponds to the name of the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd874f4-cacf-4d36-b23d-c0d2c6a546de",
   "metadata": {},
   "outputs": [],
   "source": [
    " # import os\n",
    " # print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f284bd-81c4-453b-8a36-8a1a8ba2928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blank', 'hog']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = os.listdir(train_dir)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c56e5-f988-40d3-87f6-b28ac0fd0132",
   "metadata": {},
   "source": [
    "# count blank images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51a9654-c27c-4998-854a-732853450790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leghth of hog images:  978\n",
      "length of blank images:  2213\n"
     ]
    }
   ],
   "source": [
    "hog_path = os.path.join(train_dir,\"hog\")\n",
    "hog_images = os.listdir(hog_path)\n",
    "print(\"leghth of hog images: \", len(hog_images))\n",
    "blank_path = os.path.join(train_dir, \"blank\")\n",
    "blank_images = os.listdir(blank_path)\n",
    "print(\"length of blank images: \", len(blank_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c87543-eb7e-46f7-a6df-07d1df8a955b",
   "metadata": {},
   "source": [
    "# Image path display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c117d-b1f1-4acb-80f9-c56760bce2a7",
   "metadata": {},
   "source": [
    "Display the path of one image of the blank class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e0a1cd-b7bb-4b25-a39e-8f5868a8388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZJ000005.jpg\n",
      "data_binary\\train\\hog\\ZJ000005.jpg\n",
      "ZJ000013.jpg\n",
      "data_binary\\train\\blank\\ZJ000013.jpg\n"
     ]
    }
   ],
   "source": [
    "hog_image_name = hog_images[0]\n",
    "print(hog_image_name)\n",
    "\n",
    "hog_image_path = os.path.join(hog_path, hog_image_name)\n",
    "print(hog_image_path)\n",
    "\n",
    "blank_image_name = blank_images[0]\n",
    "print(blank_image_name)\n",
    "\n",
    "blank_image_path = os.path.join(blank_path, blank_image_name)\n",
    "print(blank_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197db09-e014-4a87-a19a-4bbc92f41e9b",
   "metadata": {},
   "source": [
    "# print out the mode and size for the blank image sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc879f36-57c2-4667-b82a-865b168ca64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hog image:  RGB (960, 540)\n",
      "Blank image:  RGB (960, 540)\n"
     ]
    }
   ],
   "source": [
    "hog_img_pil = Image.open(hog_image_path)\n",
    "print(\"Hog image: \", hog_img_pil.mode, hog_img_pil.size)\n",
    "\n",
    "blank_img_pil = Image.open(blank_image_path)\n",
    "print(\"Blank image: \", blank_img_pil.mode, blank_img_pil.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83eda5d-d8de-406d-aa8a-5a6acb2c344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 22, 22)\n"
     ]
    }
   ],
   "source": [
    "pixels = hog_img_pil.load()\n",
    "print(pixels[0, 0])  # Sample pixel value at top-left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7608eb2-05d2-4339-b114-85eeae0be7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_img_gray = hog_img_pil.convert(\"L\")\n",
    "hog_img_gray.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720ef47-18e1-4853-ab9f-96efa61d9582",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68d3350-a164-44a5-b5c5-b39944b28086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToRGB:\n",
    "    def __call__(self, img):\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88fb481d-3c8e-4188-93e6-5e510ba3829d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.transforms.transforms.Compose'>\n",
      "Compose(\n",
      "    <__main__.ConvertToRGB object at 0x0000021522CEF4D0>\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define transformation to apply to the images\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        ConvertToRGB(),  # Convert images to RGB format if not already\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "        # Convert images to tensors\n",
    "        transforms.ToTensor()\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(type(transform))\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36fccf7e-6f77-4bc1-8b07-2135b799eb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3191\n",
      "    Root location: data_binary\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               <__main__.ConvertToRGB object at 0x0000021522CEF4D0>\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset using `ImageFolder`\n",
    "dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "889a6fd7-b339-4328-9d8f-3d3cbe179faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blank', 'hog']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7956a14-35bf-467b-826b-5278e3723ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data_binary\\\\train\\\\blank\\\\ZJ000013.jpg', 0)\n",
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "im = dataset.imgs\n",
    "print(im[0])\n",
    "\n",
    "distinct_classes = {x[1] for x in im}\n",
    "print(distinct_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ecc3a34-07cf-4ea8-aeee-b01ae07fefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, don't change this!\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d259ffa-7b88-4b0c-b724-0860b25aec59",
   "metadata": {},
   "source": [
    "# Print out the length of the validation dataset and the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea4823d3-618f-40f0-a89a-74cd2c355c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 2553\n",
      "Length of validation set: 638\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of training set: {len(train_dataset)}\")\n",
    "print(f\"Length of validation set: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6f169-9068-48ac-a0d3-90eb68645900",
   "metadata": {},
   "source": [
    "# Validation data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4eff5ac-1e73-4f77-8215-c724c5981dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets --upgrade\n",
    "# !jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "# !jupyter nbextension install --py widgetsnbextension --sys-prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c283a84b-d058-42ea-bef3-2d88b4fd3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(dataset):\n",
    "    c = Counter(x[1] for x in tqdm(dataset))\n",
    "    class_to_index = dataset.dataset.class_to_idx\n",
    "    return pd.Series({cat: c[idx] for cat, idx in class_to_index.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c6f7896-e038-423d-b453-4273b82c06b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05908d7d3f69418185235cf211a35b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2553 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "blank    1749\n",
       "hog       804\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = class_counts(train_dataset)\n",
    "train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a650b1f1-3628-4097-9603-5b372d981c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_counts.sort_values().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6c3a7a-f526-4403-8b08-450caf548518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de83dd97cbb149fca692c02f470a9978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_counts = class_counts(val_dataset)\n",
    "\n",
    "# Make a bar chart from the function output\n",
    "val_counts.sort_values().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bf5c8-1fa4-49ae-8761-ff8288b11487",
   "metadata": {},
   "source": [
    " From both visualizations, we see two things:\n",
    "\n",
    "About two-thirds of the data is the \"blank\" label.\n",
    "Both the training and validation set are similarly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2b0c3-9d7e-44f5-8030-6569d443253c",
   "metadata": {},
   "source": [
    "# Create the validation loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "506c1f0d-7c03-4c91-82e8-6d29422a2301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "# Important, don't change this!\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(type(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181190ca-d806-49ab-a926-7dcda96c879b",
   "metadata": {},
   "source": [
    "# Building a shallow neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ea2fbd-f20a-45bc-8d43-613c503b8398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch of images torch.Size([32, 3, 224, 224])\n",
      "Shape of batch of labels: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# This gives you [batch_size, channels, height, width] for images\n",
    "image_shape = images.shape\n",
    "print(\"Shape of batch of images\", image_shape)\n",
    "\n",
    "# This gives you [batch_size] for labels\n",
    "label_shape = labels.shape\n",
    "print(\"Shape of batch of labels:\", label_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fd004bf-5192-4950-b14c-914fb089f6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "820dc4ad-f609-4d46-a166-1ac7847b3864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of flattened tensor:torch.Size([32, 150528])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "tensor_flatten = flatten(images)\n",
    "\n",
    "# Print the shape of the flattened tensor\n",
    "print(f\"shape of flattened tensor:{tensor_flatten.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee4ef9e7-05a1-4ee6-9d7d-d8076ce0c41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: <class 'torch.nn.modules.container.Sequential'>\n",
      "model structure:\n",
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=150528, out_features=512, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Image size from our transformer\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * height * width, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "print(\"model type:\", type(model))\n",
    "print(\"model structure:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28fbc527-fb7a-48a2-b85c-12d2a7af912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=150528, out_features=512, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create the Output layer\n",
    "\n",
    "output_layer = nn.Linear(128, 2)\n",
    "model.append(output_layer)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8709461a-a07b-4c97-9a76-db1be9252ec1",
   "metadata": {},
   "source": [
    "We can see three different types of layers being used:\n",
    "\n",
    "nn.Flatten flattens the three-dimensional input tensors to the one-dimensional tensors that the next layers expect.\n",
    "nn.Linear is a standard dense, or fully-connected, layer. It takes two arguments, the number of inputs coming into this layer and the number of outputs produced by this layer.\n",
    "nn.ReLU performs the rectified linear unit activation. Activation functions are necessary for neural networks to work, and ReLU is a popular choice.\n",
    "The last nn.Linear is our output layer. It must have 128 inputs, to match the output of the preceding layer, and it must have 2 outputs to match the two classes. Note that there's no activation function applied after the output layer. This means that the outputs of this layer are the logits. Later on, these logits will be the input to a normalization function, called softmax in this case, that will turn the logits into probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300ba9be-b779-40c4-b868-c31d79669df9",
   "metadata": {},
   "source": [
    "# Training Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56ce2a-7b78-4f74-b21c-40f0243d8558",
   "metadata": {},
   "source": [
    "# Epoch Loss Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d71df6f6-fbd4-443d-908b-6e3563c2fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bd9e259-a07e-4821-893e-30bf858466d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40c166-55f5-47c1-8213-97e9f0f3967b",
   "metadata": {},
   "source": [
    "model: The PyTorch model we built with a specific architecture\n",
    "\n",
    "optimizer: The optimizer that will be used to best adjust the model weights\n",
    "\n",
    "loss_fn: The loss function that the optimizer is trying to minimize\n",
    "\n",
    "data_loader: The DataLoader object for the training dataset that makes it easy to iterate over batches\n",
    "\n",
    "device: The device where we're going to place the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45f8cd93-761d-465c-8e4b-201101ed9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_fn, data_loader, device=\"cpu\"):\n",
    "    # We'll report the loss function's average value at the end of the epoch.\n",
    "    training_loss = 0.0\n",
    "\n",
    "    # The train method simply sets the model in training mode. No training\n",
    "    # has happened.\n",
    "    model.train()\n",
    "\n",
    "    # We iterate over all batches in the training set to complete one epoch\n",
    "    for inputs, targets in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        # Sets the gradients to zero. We need to do this every time.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Unpack images (X) and labels (y) from the batch and add those\n",
    "        # tensors to the specified device.\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # We make a forward pass through the network and obtain the logits.\n",
    "        # With the logits, we can calculate our loss.\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        # After calculating our loss, we calculate the numerical value of\n",
    "        # the derivative of our loss function with respect to all the\n",
    "        # trainable model weights. Once we have the gradients calculated,\n",
    "        # we let the optimizer take a \"step\", in other words, update or\n",
    "        # adjust the model weights.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # We increment the training loss for the current batch\n",
    "        training_loss += loss.data.item() * inputs.size(0)\n",
    "\n",
    "    # We calculate the training loss over the completed epoch\n",
    "    return training_loss / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4d6f249-dc10-4278-8307-cf1d78b4829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a734edcb8443fb8f1b69496f72ccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss during the training epoch was 3.57.\n"
     ]
    }
   ],
   "source": [
    "loss_value = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
    "print(f\"The average loss during the training epoch was {loss_value:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a71a44-d7c9-4135-85f8-881f847a8482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
